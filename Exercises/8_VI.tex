\documentclass[a4paper,10pt,fleqn]{article}

\usepackage{a4wide,amsmath,amsthm,amssymb,bbm,fancyhdr}
\usepackage{ifthen,color,enumerate,comment,dsfont,pdfsync,framed,todonotes,enumitem}

\newcommand{\titre}[1]{\textbf{\textsc{#1}}}

\RequirePackage[T1]{fontenc}

\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{enumitem}
\newcommand{\eqsp}{\,}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\rmd}{\mathrm{d}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\rset}{\ensuremath{\mathbb{R}}}
\renewcommand{\P}{\ensuremath{\operatorname{P}}}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\E}{\ensuremath{\mathbb{E}}}
\newcommand{\rme}{\ensuremath{\mathrm{e}}}
\newcommand{\calH}{\ensuremath{\mathcal{H}}}
\newcommand{\xset}{\ensuremath{\mathsf{X}}}
\newcommand{\V}{\ensuremath{\mathbb{V}}}
\newcommand{\Sb}{\ensuremath{\mathbb{S}}}
\newcommand{\gaus}{\ensuremath{\mathcal{N}}}
\newcommand{\HH}{\ensuremath{\mathcal{H}}}
\newcommand{\F}{\ensuremath{\mathcal{F}}}
\newcommand{\W}{\ensuremath{\mathcal{W}}}
\newcommand{\X}{\ensuremath{\mathcal{X}}}
\newcommand{\1}{\ensuremath{\mathbbm{1}}}
\newcommand{\dlim}{\ensuremath{\stackrel{\mathcal{L}}{\longrightarrow}}}
\newcommand{\plim}{\ensuremath{\stackrel{\mathrm{P}}{\longrightarrow}}}
\newcommand{\PP}{\ensuremath{\mathbb{P}}}
\newcommand{\p}{\ensuremath{\mathbb{P}}}
\newcommand{\eps}{\varepsilon}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\hatk}{\widehat K}
\newcommand{\f}{\varphi}
\newcommand{\Id}{\textsf{Id}}
\newcommand{\bfU}{\mathbf{U}}
\newcommand{\bfX}{\mathbf{X}}
\newcommand{\bfs}{\mathbf{\Sigma}}
\newcommand{\bfA}{\mathbf{A}}
\newcommand{\bfV}{\mathbf{V}}
\newcommand{\bfB}{\mathbf{B}}
\newcommand{\bfI}{\mathbf{I}}
\newcommand{\bfD}{\mathbf{D}}
\newcommand{\bfK}{\mathbf{K}}
\newcommand{\argmin}{\mathop{\textrm{argmin}}}
\newcommand{\argmax}{\mathop{\textrm{argmax}}}
\newcommand{\crit}{\mathop{\textrm{crit}}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\pc}{\pi_{\mathcal{C}}}


% Style


\newtheorem{theorem}{Theorem}


\begin{document}

%\noindent Statistiques computationnelles \hfill Sorbonne Universit\'e 
% 2022-2023

\noindent\hrulefill

\begin{center}
\textsc{Inf\'erence variationnelle}
\end{center}
\hrulefill

\medskip


\section{Warm-up}
Soit $(Z,X)$ un couple de variables al\'eatoires sur $\rset^d\times \rset^m$. On note $(z,x)\mapsto p(z,x)$ la densit\'e jointe de la loi de $(X,Z)$ par rapport \`a la mesure de Lebesgue. On consid\`ere \'egalement une famille $\mathcal{Q}$ de densit\'es par rapport \`a la mesure de Lebesgue sur $\rset^d$. On introduit alors la ELBO (Evidence Lower Bound) de la fa\c con suivante: pour tout $q\in\mathcal{Q}$,
$$
\mathcal{L}(q) = \mathbb{E}_q\left[\log\frac{p(Z,X)}{q(Z)}\middle | X\right] = \int \log\frac{p(z,X)}{q(z)}q(z) \mathrm{d} z\,.
$$
\begin{enumerate}
\item Montrer que $\mathrm{KL}(q\|p(\cdot|X)) = \log p(X) - \mathcal{L}(q) $.
\item En d\'eduire que $\mathcal{L}(q) \leq \log p(X)$.
\item Supposons que $q$ soit de la forme $q:(z_1,\ldots,z_d)\mapsto \prod_{j=1}^dq_j(z_j)$ o\`u les $\{q_j\}_{1\leq j\leq d}$ sont des densit\'es sur $\rset$. Fixons $1\leq j_0 \leq d$ et tous les $q_j$, $j\neq j_0$. Montrez que 
$$
q_{j_0}^* = \mathrm{Argmax}_{q_{j_0}} \mathcal{L}(q) 
$$
est la densit\'e proportionnelle \`a $z_j \mapsto \exp\{\mathbb{E}_{-j_0}[\log p (z_{j_0},Z_{-j_0},X)]\}$, o\`u $Z_{-j_0} = (Z_j)_{j\neq j_0}$ et $\mathbb{E}_{-j_0}$ est l'esp\'erance lorsque la densit\'e de $Z_{-j_0}$ est $\prod_{j=1,j\neq j_0}^dq_j$.


\end{enumerate}

\section{Inf\'erence variationnelle : mod\`ele gaussien}
Soient $\alpha_0$ et $\beta_0$ deux re\'els strictement positifs et $\mu_0$ un r\'eel. On consid\`ere les variables al\'eatoires suivantes : $\sigma^2 \sim\mathcal{IG}(\alpha_0,\beta_0)$, $\mu\sim\mathcal{N}(\mu_0,\sigma^2)$ et $X = (X_i)_{1\leq i\leq n}\sim\otimes_{i=1}^n\mathcal{N}(\mu,\sigma^2)$ o\`u $\mathcal{IG}$ est la loi inverse gamma.
\begin{enumerate}
\item \'Ecrire la densit\'e jointe des variables $Z=(\mu,\sigma^2)$ et $X$.
\item On consid\`ere une famille variationnelle o\`u $q:(\mu,\sigma^2)\mapsto q_\mu(\mu)q_{\sigma^2}(\sigma^2)$. \'Ecrire la ELBO associ\'ee.
\item \'Ecire la mise \`a jour de $q_\mu$ dans une \'etape de l'algorithme CAVI. 
\item \'Ecire la mise \`a jour de $q_{\sigma^2}$ dans une \'etape de l'algorithme CAVI. 
\end{enumerate}

\section{Inf\'erence variationelle pour les mod\`eles exponentiels}
On consid\`ere un couple de variables al\'eatoires $(Z,X)\in\mathbb{R}^d\times \mathbb{R}^m$. On note $(z,x) \mapsto p(z,x)$ la densit\'e jointe de ce couple par rapport \`a la mesure de Lebesgue. Nous souhaitons utiliser dans cet exercice une approche variationnelle pour estimer la loi a posteriori $p(z|x)$. Pour cela on se donne une famille de densit\'es sur $\mathbb{R}^d$:
$$
\mathcal{Q} = \left\{(z_1,\ldots,z_d)\mapsto \prod_{j=1}^dq_j(z_j)\eqsp;\eqsp q_j\; \mathrm{est\,une\,densit\acute e\,sur\,\mathbb{R}}\right\}\eqsp.
$$
\begin{enumerate}
\item Rappeler l'algorithme CAVI (Coordinate Ascent Variational Inference) pour estimer it\'erativement $q^*$.
\item Supposons que le mod\`ele soit tel que pour tout $j\in\mathbb{R}$, 
$$
p(z_j|z_{-j},x) = h(z_j)\mathrm{exp}(\eta(z_{-j})^Ts(z_j) - a(z_{-j}))\eqsp,
$$ 
o\`u $z_{-j} = (z_u)_{1\leqslant u\leqslant d, u \neq j}$ et o\`u $\eta$, $s$ et $a$ sont des fonctions connues (la d\'ependance en $x$ de ces fonctions est omise par simplicit\'e). Montrer que si les densit\'es $(q_u)_{1\leqslant u\leqslant d, u \neq j}$ sont fix\'ees alors la mise \`a jour de l'algorithme CAVI de la $j$-\`eme densit\'e est  (\`a une constante multiplicative pr\`es),
$$
q^*_j(z_j) \mapsto h(z_j) \mathrm{exp}\left\{\mathbb{E}_{-j}[\eta(Z_{-j})^Ts(Z_j)]\right\}\eqsp,
$$
o\`u $\mathbb{E}_{-j}$ est l'esp\'erance sous la loi de densit\'e $\prod_{u=1, u\neq j}^d q_u(z_u)$.
\item La convergence de l'algorithme CAVI  d\'epend-elle de l'initialisation des densit\'e $(q_u)_{1\leqslant u\leqslant d}$ ?
\end{enumerate}
\end{document}